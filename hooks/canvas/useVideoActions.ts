'use client';

import { useCallback } from 'react';
import { useCanvasStore } from '@/lib/store';
import { TextElement, ImageElement, VideoElement } from '@/lib/types';
import {
  TEXT_NODE_DEFAULT_SIZE,
  IMAGE_NODE_DEFAULT_SIZE,
  VIDEO_NODE_DEFAULT_SIZE,
  getVideoNodeSize,
  detectVideoAspectRatio,
} from '@/lib/constants/node-sizes';
import { generateNodeId } from '@/lib/services/node-management.service';
import { generateVideoFromText } from '@/lib/api-mock';
import type { ReshootMotionType } from '@/lib/types';

// è¡Œçº§æ³¨é‡Šï¼šè¾¹ç¼˜æ ·å¼å¸¸é‡
const EDGE_GENERATING_STYLE = { stroke: '#a855f7', strokeWidth: 1 };
const EDGE_DEFAULT_STYLE = { stroke: '#64748b', strokeWidth: 1 };
const EDGE_ERROR_STYLE = { stroke: '#ef4444', strokeWidth: 1 };

/**
 * è§†é¢‘æ“ä½œ Hook
 * 
 * èŒè´£ï¼šå¤„ç†å„ç§è§†é¢‘åˆ›å»ºå’Œæ“ä½œ
 * - æ–‡ç”Ÿè§†é¢‘
 * - å›¾ç”Ÿè§†é¢‘
 * - é•œå¤´æ§åˆ¶é‡æ‹
 * - å»¶é•¿è§†é¢‘
 */
export interface UseVideoActionsOptions {
  setEdges: (updater: (edges: any[]) => any[]) => void;
  resetConnectionMenu: () => void;
  createVideoNodeFromImage: (
    sourceImage: ImageElement,
    flowPosition: { x: number; y: number },
    targetHandle: 'start-image' | 'end-image',
    placementDirection: 'right' | 'below'
  ) => void;
  connectionMenu: {
    sourceNodeId: string | null;
    position: { x: number; y: number };
  };
  reactFlowInstance: any;
}

export interface UseVideoActionsReturn {
  handleTextToVideo: (sourceNode: TextElement, aspectRatio: '9:16' | '16:9') => Promise<void>;
  handleImageToVideo: (sourceNode: ImageElement, aspectRatio: '9:16' | '16:9') => void;
  handleGenerateVideoFromImage: () => void;
  handleGenerateReshoot: (motionType: ReshootMotionType) => Promise<void>;
  handleShowExtendVideo: () => void;
}

export function useVideoActions(options: UseVideoActionsOptions): UseVideoActionsReturn {
  const {
    setEdges,
    resetConnectionMenu,
    createVideoNodeFromImage,
    connectionMenu,
    reactFlowInstance,
  } = options;

  const elements = useCanvasStore(state => state.elements);
  const addElement = useCanvasStore(state => state.addElement);
  const updateElement = useCanvasStore(state => state.updateElement);

  /**
   * æ–‡ç”Ÿè§†é¢‘
   */
  const handleTextToVideo = useCallback(
    async (sourceNode: TextElement, aspectRatio: '9:16' | '16:9') => {
      resetConnectionMenu();

      const videoSize = getVideoNodeSize(aspectRatio);

      const newVideoId = generateNodeId('video');
      const newVideo: VideoElement = {
        id: newVideoId,
        type: 'video',
        src: '',
        thumbnail: '',
        duration: 0,
        status: 'generating',
        progress: 0,
        position: {
          x: sourceNode.position.x + (sourceNode.size?.width || TEXT_NODE_DEFAULT_SIZE.width) + 100,
          y: sourceNode.position.y,
        },
        size: videoSize,
        promptText: sourceNode.text,
        generatedFrom: {
          type: 'text',
          sourceIds: [sourceNode.id],
          prompt: sourceNode.text,
        },
      };

      addElement(newVideo);

      // åˆ›å»ºè¿çº¿
      setEdges((eds: any[]) => [
        ...eds,
        {
          id: `edge-${sourceNode.id}-${newVideoId}-prompt-text`,
          source: sourceNode.id,
          target: newVideoId,
          targetHandle: 'prompt-text',
          type: 'default',
          animated: true,
          style: EDGE_GENERATING_STYLE,
        },
      ]);

      try {
        const result = await generateVideoFromText(sourceNode.text, aspectRatio);

        updateElement(newVideoId, {
          status: 'ready',
          src: result.videoUrl,
          thumbnail: result.thumbnail,
          duration: result.duration,
          progress: 100,
          mediaGenerationId: result.mediaGenerationId,
          promptText: sourceNode.text,
          generatedFrom: {
            type: 'text',
            sourceIds: [sourceNode.id],
            prompt: sourceNode.text,
          },
        } as Partial<VideoElement>);

        setEdges((eds: any[]) =>
          eds.map((edge: any) =>
            edge.id === `edge-${sourceNode.id}-${newVideoId}-prompt-text`
              ? { ...edge, animated: false, style: EDGE_DEFAULT_STYLE }
              : edge
          )
        );

        console.log('âœ… ä»æ–‡æœ¬èŠ‚ç‚¹ç”Ÿæˆè§†é¢‘:', sourceNode.text);
      } catch (error) {
        console.error('âŒ ç”Ÿæˆè§†é¢‘å¤±è´¥:', error);
        setEdges((eds: any[]) =>
          eds.map((edge: any) =>
            edge.id === `edge-${sourceNode.id}-${newVideoId}-prompt-text`
              ? { ...edge, animated: false, style: EDGE_ERROR_STYLE }
              : edge
          )
        );
        alert('ç”Ÿæˆè§†é¢‘å¤±è´¥ï¼Œè¯·é‡è¯•');
      }
    },
    [addElement, updateElement, setEdges, resetConnectionMenu]
  );

  /**
   * å›¾ç”Ÿè§†é¢‘
   */
  const handleImageToVideo = useCallback(
    (sourceNode: ImageElement, aspectRatio: '9:16' | '16:9') => {
      resetConnectionMenu();

      const flowPosition = {
        x: sourceNode.position.x + (sourceNode.size?.width || IMAGE_NODE_DEFAULT_SIZE.width) + 100,
        y: sourceNode.position.y,
      };

      createVideoNodeFromImage(sourceNode, flowPosition, 'start-image', 'right');
      console.log('âœ… ä»å›¾ç‰‡èŠ‚ç‚¹åˆ›å»ºè§†é¢‘èŠ‚ç‚¹:', sourceNode.id);
    },
    [createVideoNodeFromImage, resetConnectionMenu]
  );

  /**
   * ä»å›¾ç‰‡ç”Ÿæˆè§†é¢‘ï¼ˆè‡ªåŠ¨æ ¹æ®å›¾ç‰‡æ¯”ä¾‹ï¼‰
   */
  const handleGenerateVideoFromImage = useCallback(() => {
    const sourceNodeId = connectionMenu.sourceNodeId;
    if (!sourceNodeId) return;

    const sourceNode = elements.find(
      (el) => el.id === sourceNodeId && el.type === 'image'
    ) as ImageElement | undefined;

    if (!sourceNode) {
      resetConnectionMenu();
      return;
    }

    const aspectRatio = detectVideoAspectRatio(
      sourceNode.size?.width || 320,
      sourceNode.size?.height || 180
    );

    console.log('ğŸ¬ æ ¹æ®å›¾ç‰‡æ¯”ä¾‹è‡ªåŠ¨ç”Ÿæˆè§†é¢‘:', aspectRatio);
    handleImageToVideo(sourceNode, aspectRatio);
  }, [connectionMenu.sourceNodeId, elements, handleImageToVideo, resetConnectionMenu]);

  /**
   * é•œå¤´æ§åˆ¶é‡æ‹
   */
  const handleGenerateReshoot = useCallback(
    async (motionType: ReshootMotionType) => {
      const sourceNodeId = connectionMenu.sourceNodeId;
      if (!sourceNodeId) return;

      const sourceNode = elements.find((el) => el.id === sourceNodeId) as VideoElement | undefined;
      if (!sourceNode) return;

      resetConnectionMenu();

      // 1. åˆ›å»ºæ–°çš„è§†é¢‘èŠ‚ç‚¹
      const newVideoId = generateNodeId('video');
      const flowPosition = reactFlowInstance.screenToFlowPosition({
        x: connectionMenu.position.x,
        y: connectionMenu.position.y,
      });

      const newVideo: VideoElement = {
        id: newVideoId,
        type: 'video',
        src: '',
        thumbnail: '',
        duration: 0,
        status: 'generating',
        progress: 0,
        position: { x: flowPosition.x, y: flowPosition.y },
        size: sourceNode.size || VIDEO_NODE_DEFAULT_SIZE,
        generatedFrom: {
          type: 'reshoot',
          sourceIds: [sourceNode.id],
        },
      };

      addElement(newVideo);

      // 2. åˆ›å»ºè¿çº¿
      const edgeId = `edge-${sourceNode.id}-${newVideoId}-reshoot`;
      setEdges((eds: any[]) => [
        ...eds,
        {
          id: edgeId,
          source: sourceNode.id,
          target: newVideoId,
          type: 'default',
          animated: true,
          style: EDGE_GENERATING_STYLE,
          label: 'é•œå¤´æ§åˆ¶',
        },
      ]);

      // 3. è°ƒç”¨ API ç”Ÿæˆ
      try {
        const effectiveMediaId = sourceNode.mediaGenerationId;

        if (!effectiveMediaId) {
          throw new Error('æºè§†é¢‘ç¼ºå°‘ mediaGenerationId');
        }

        const aspectRatio = detectVideoAspectRatio(
          sourceNode.size?.width || 640,
          sourceNode.size?.height || 360
        );

        const { generateVideoReshoot } = await import('@/lib/api-mock');
        const result = await generateVideoReshoot(
          effectiveMediaId,
          motionType,
          aspectRatio as any
        );

        updateElement(newVideoId, {
          status: 'ready',
          src: result.videoUrl,
          thumbnail: result.thumbnail,
          duration: result.duration,
          mediaGenerationId: result.mediaGenerationId,
          progress: 100,
          readyForGeneration: true,
        } as Partial<VideoElement>);

        setEdges((eds: any[]) =>
          eds.map((edge: any) =>
            edge.id === edgeId
              ? { ...edge, animated: false, style: EDGE_DEFAULT_STYLE }
              : edge
          )
        );

        console.log('âœ… é•œå¤´æ§åˆ¶è§†é¢‘ç”ŸæˆæˆåŠŸ');
      } catch (error) {
        console.error('âŒ é•œå¤´æ§åˆ¶è§†é¢‘ç”Ÿæˆå¤±è´¥:', error);
        updateElement(newVideoId, { status: 'error' } as Partial<VideoElement>);
        setEdges((eds: any[]) =>
          eds.map((edge: any) =>
            edge.id === edgeId
              ? { ...edge, animated: false, style: EDGE_ERROR_STYLE }
              : edge
          )
        );
      }
    },
    [connectionMenu.sourceNodeId, connectionMenu.position, elements, addElement, setEdges, updateElement, reactFlowInstance, resetConnectionMenu]
  );

  /**
   * å»¶é•¿è§†é¢‘ - åˆ›å»º pending èŠ‚ç‚¹
   */
  const handleShowExtendVideo = useCallback(() => {
    const sourceNodeId = connectionMenu.sourceNodeId;
    if (!sourceNodeId) return;

    const sourceNode = elements.find((el) => el.id === sourceNodeId) as VideoElement | undefined;
    if (!sourceNode) return;

    resetConnectionMenu();

    // 1. åˆ›å»º pending çŠ¶æ€çš„è§†é¢‘èŠ‚ç‚¹
    const newVideoId = generateNodeId('video');
    const flowPosition = reactFlowInstance.screenToFlowPosition({
      x: connectionMenu.position.x,
      y: connectionMenu.position.y,
    });

    const newVideo: VideoElement = {
      id: newVideoId,
      type: 'video',
      src: '',
      thumbnail: '',
      duration: 0,
      status: 'pending',
      progress: 0,
      position: { x: flowPosition.x, y: flowPosition.y },
      size: sourceNode.size || VIDEO_NODE_DEFAULT_SIZE,
      readyForGeneration: false,
      generatedFrom: {
        type: 'extend',
        sourceIds: [sourceNode.id],
      },
    };

    addElement(newVideo);

    // 2. åˆ›å»ºè¿çº¿
    const edgeId = `edge-${sourceNode.id}-${newVideoId}-extend`;
    setEdges((eds: any[]) => [
      ...eds,
      {
        id: edgeId,
        source: sourceNode.id,
        target: newVideoId,
        type: 'default',
        animated: false,
        style: EDGE_GENERATING_STYLE,
        label: 'å»¶é•¿',
      },
    ]);

    console.log('âœ… å»¶é•¿è§†é¢‘èŠ‚ç‚¹å·²åˆ›å»ºï¼Œç­‰å¾…ç”¨æˆ·è¾“å…¥æç¤ºè¯');
  }, [connectionMenu.sourceNodeId, connectionMenu.position, elements, addElement, setEdges, reactFlowInstance, resetConnectionMenu]);

  return {
    handleTextToVideo,
    handleImageToVideo,
    handleGenerateVideoFromImage,
    handleGenerateReshoot,
    handleShowExtendVideo,
  };
}

