'use client';

import { useCallback, useRef } from 'react';
import { useCanvasStore } from '@/lib/store';
import { VideoElement, ImageElement } from '@/lib/types';
import { VIDEO_NODE_DEFAULT_SIZE, detectAspectRatio } from '@/lib/constants/node-sizes';
import { analyzeImageForVideoPrompt } from '@/lib/tools/vision-api';
import { generateVideoFromText, generateVideoFromImages } from '@/lib/api-mock';
import { generateNodeId } from '@/lib/services/node-management.service';

// è¡Œçº§æ³¨é‡Šï¼šè¾¹ç¼˜æ ·å¼å¸¸é‡
const EDGE_GENERATING_STYLE = { stroke: '#a855f7', strokeWidth: 1 };
const EDGE_ERROR_STYLE = { stroke: '#ef4444', strokeWidth: 1 };
const EDGE_DEFAULT_STYLE = { stroke: '#64748b', strokeWidth: 1 };

/**
 * è§†é¢‘ç”Ÿæˆ Hook
 * 
 * èŒè´£ï¼šå¤„ç†æ‰€æœ‰è§†é¢‘ç”Ÿæˆç›¸å…³çš„é€»è¾‘
 * - æ–‡ç”Ÿè§†é¢‘
 * - å›¾ç”Ÿè§†é¢‘
 * - é¦–å°¾å¸§è§†é¢‘
 * - è§†é¢‘å»¶é•¿
 * - é•œå¤´æ§åˆ¶é‡æ‹
 */
export interface UseVideoGenerationOptions {
  setEdges: (updater: (edges: any[]) => any[]) => void;
}

export interface UseVideoGenerationReturn {
  maybeStartVideo: (videoId: string) => Promise<void>;
  activeGenerationRef: React.MutableRefObject<Set<string>>;
}

export function useVideoGeneration(options: UseVideoGenerationOptions): UseVideoGenerationReturn {
  const { setEdges } = options;
  
  const updateElement = useCanvasStore(state => state.updateElement);
  const addElement = useCanvasStore(state => state.addElement);
  
  // è¡Œçº§æ³¨é‡Šï¼šè¿½è¸ªæ­£åœ¨ç”Ÿæˆçš„è§†é¢‘ï¼Œé¿å…é‡å¤ç”Ÿæˆ
  const activeGenerationRef = useRef<Set<string>>(new Set());

  /**
   * æ ¸å¿ƒè§†é¢‘ç”Ÿæˆå‡½æ•°
   * æ£€æŸ¥è§†é¢‘èŠ‚ç‚¹çŠ¶æ€ï¼Œæ‰§è¡Œç”Ÿæˆé€»è¾‘
   */
  const maybeStartVideo = useCallback(
    async (videoId: string) => {
      // è¡Œçº§æ³¨é‡Šï¼šé˜²æ­¢é‡å¤ç”Ÿæˆ
      if (activeGenerationRef.current.has(videoId)) {
        return;
      }

      const { elements: storeElements } = useCanvasStore.getState();
      const videoElement = storeElements.find((el) => el.id === videoId) as VideoElement | undefined;

      if (!videoElement) return;

      // è¡Œçº§æ³¨é‡Šï¼šåªå¤„ç†æ’é˜Ÿä¸­çš„è§†é¢‘
      if (videoElement.status !== 'queued') {
        return;
      }

      let promptText = videoElement.promptText?.trim();
      const startImageId = videoElement.startImageId;
      const endImageId = videoElement.endImageId;
      const generationCount = videoElement.generationCount || 1;

      const hasAtLeastOneImage = Boolean(startImageId || endImageId);
      
      // è¡Œçº§æ³¨é‡Šï¼šæ™ºèƒ½è§†é¢‘ç”Ÿæˆ - å¦‚æœæœ‰å›¾ç‰‡ä½†æ²¡æœ‰æç¤ºè¯ï¼Œä½¿ç”¨ VL åˆ†æ
      if (hasAtLeastOneImage && !promptText) {
        const { apiConfig } = useCanvasStore.getState();
        const dashScopeApiKey = apiConfig.dashScopeApiKey;
        
        if (!dashScopeApiKey) {
          console.warn('âš ï¸ æ²¡æœ‰é…ç½® DashScope API Keyï¼Œæ— æ³•ä½¿ç”¨æ™ºèƒ½åˆ†æ');
          updateElement(videoId, {
            status: 'pending',
            readyForGeneration: false,
          } as Partial<VideoElement>);
          return;
        }

        // è¡Œçº§æ³¨é‡Šï¼šè·å–å›¾ç‰‡ä¿¡æ¯
        const startImage = startImageId 
          ? storeElements.find(el => el.id === startImageId) as ImageElement | undefined
          : null;
        const endImage = endImageId 
          ? storeElements.find(el => el.id === endImageId) as ImageElement | undefined
          : null;
        
        const actualStartImage = startImage || endImage;
        if (!actualStartImage?.src) {
          console.warn('âš ï¸ æ‰¾ä¸åˆ°æœ‰æ•ˆçš„å›¾ç‰‡æº');
          updateElement(videoId, {
            status: 'pending',
            readyForGeneration: false,
          } as Partial<VideoElement>);
          return;
        }

        try {
          updateElement(videoId, {
            status: 'generating',
            progress: 5,
          } as Partial<VideoElement>);

          console.log('ğŸ” ä½¿ç”¨ VL åˆ†æå›¾ç‰‡ç”Ÿæˆè§†é¢‘æç¤ºè¯...');
          
          // è¡Œçº§æ³¨é‡Šï¼šå‡†å¤‡å›¾ç‰‡æ•°æ®
          let startImageData = actualStartImage.src;
          if (actualStartImage.base64) {
            startImageData = actualStartImage.base64.startsWith('data:') 
              ? actualStartImage.base64 
              : `data:image/png;base64,${actualStartImage.base64}`;
          }
          
          let endImageData: string | null = null;
          if (startImage && endImage && endImage.id !== startImage.id) {
            if (endImage.base64) {
              endImageData = endImage.base64.startsWith('data:') 
                ? endImage.base64 
                : `data:image/png;base64,${endImage.base64}`;
            } else if (endImage.src) {
              endImageData = endImage.src;
            }
          }

          promptText = await analyzeImageForVideoPrompt(startImageData, endImageData, dashScopeApiKey);
          console.log('âœ… VL åˆ†æå®Œæˆï¼Œç”Ÿæˆæç¤ºè¯:', promptText);
          
          updateElement(videoId, {
            promptText: promptText,
            progress: 15,
          } as Partial<VideoElement>);
        } catch (error) {
          console.error('âŒ VL åˆ†æå¤±è´¥:', error);
          updateElement(videoId, {
            status: 'error',
            readyForGeneration: false,
          } as Partial<VideoElement>);
          return;
        }
      }
      
      // è¡Œçº§æ³¨é‡Šï¼šæ£€æŸ¥æ˜¯å¦å‡†å¤‡å¥½ç”Ÿæˆ
      const ready = Boolean(promptText);

      if (!ready) {
        updateElement(videoId, {
          status: 'pending',
          readyForGeneration: ready,
        } as Partial<VideoElement>);
        return;
      }

      console.log('ğŸ¬ maybeStartVideo: å¼€å§‹ç”Ÿæˆè§†é¢‘', { videoId, generationCount, promptText });

      // è¡Œçº§æ³¨é‡Šï¼šå¦‚æœéœ€è¦ç”Ÿæˆå¤šä¸ªè§†é¢‘ï¼Œåˆ›å»ºé¢å¤–çš„èŠ‚ç‚¹
      if (generationCount > 1) {
        const basePosition = videoElement.position;
        const size = videoElement.size || VIDEO_NODE_DEFAULT_SIZE;
        const spacing = 50;

        for (let i = 1; i < generationCount; i++) {
          const newVideoId = `video-${Date.now()}-${i}`;
          const newPosition = {
            x: basePosition.x + (size.width + spacing) * i,
            y: basePosition.y,
          };

          const newVideo: VideoElement = {
            id: newVideoId,
            type: 'video',
            src: '',
            thumbnail: '',
            duration: 0,
            status: 'queued',
            progress: 0,
            position: newPosition,
            size: size,
            promptText: promptText,
            startImageId: startImageId,
            endImageId: endImageId,
            generationCount: 1,
            generatedFrom: videoElement.generatedFrom,
          };

          addElement(newVideo);

          // è¡Œçº§æ³¨é‡Šï¼šåˆ›å»ºè¿çº¿
          if (videoElement.generatedFrom?.type === 'extend' || videoElement.generatedFrom?.type === 'reshoot') {
            const sourceVideoId = videoElement.generatedFrom.sourceIds[0];
            if (sourceVideoId) {
              setEdges((eds: any[]) => [
                ...eds,
                {
                  id: `edge-${sourceVideoId}-${newVideoId}`,
                  source: sourceVideoId,
                  target: newVideoId,
                  type: 'default',
                  animated: true,
                  style: EDGE_GENERATING_STYLE,
                  label: videoElement.generatedFrom?.type === 'extend' ? 'å»¶é•¿' : 'é•œå¤´æ§åˆ¶',
                },
              ]);
            }
          } else if (startImageId) {
            setEdges((eds: any[]) => [
              ...eds,
              {
                id: `edge-${startImageId}-${newVideoId}`,
                source: startImageId,
                target: newVideoId,
                type: 'default',
                animated: true,
                style: EDGE_GENERATING_STYLE,
              },
            ]);
          }

          // è¡Œçº§æ³¨é‡Šï¼šå»¶è¿Ÿè§¦å‘ç”Ÿæˆ
          setTimeout(() => {
            maybeStartVideo(newVideoId);
          }, i * 500);
        }
      }

      // è¡Œçº§æ³¨é‡Šï¼šæ ‡è®°æ­£åœ¨ç”Ÿæˆ
      activeGenerationRef.current.add(videoId);

      updateElement(videoId, {
        status: 'generating',
        progress: 20,
        src: '',
        thumbnail: '',
      } as Partial<VideoElement>);

      // è¡Œçº§æ³¨é‡Šï¼šæ›´æ–°è¾¹ç¼˜åŠ¨ç”»
      setEdges((eds: any[]) =>
        eds.map((edge: any) =>
          edge.target === videoId
            ? { ...edge, animated: true, style: EDGE_GENERATING_STYLE }
            : edge
        )
      );

      try {
        let result;
        let generationType: 'text-to-video' | 'image-to-image' | 'extend' | 'reshoot' = 'text-to-video';
        const combinedSourceIds = new Set<string>(videoElement.generatedFrom?.sourceIds ?? []);

        // è¡Œçº§æ³¨é‡Šï¼šåˆ¤æ–­è§†é¢‘ç±»å‹å¹¶è°ƒç”¨å¯¹åº” API
        if (videoElement.generatedFrom?.type === 'extend') {
          // è¡Œçº§æ³¨é‡Šï¼šå»¶é•¿è§†é¢‘
          const sourceVideoId = videoElement.generatedFrom.sourceIds[0];
          if (!sourceVideoId) {
            throw new Error('ç¼ºå°‘æºè§†é¢‘èŠ‚ç‚¹ID');
          }

          const sourceVideo = storeElements.find(el => el.id === sourceVideoId) as VideoElement | undefined;
          if (!sourceVideo || !sourceVideo.mediaGenerationId) {
            throw new Error('æºè§†é¢‘ç¼ºå°‘ mediaGenerationId');
          }

          const aspectRatio = detectAspectRatio(
            videoElement.size?.width || 640,
            videoElement.size?.height || 360
          );

          const { generateVideoExtend } = await import('@/lib/api-mock');
          result = await generateVideoExtend(
            sourceVideo.mediaGenerationId,
            promptText || '',
            aspectRatio as any
          );
          generationType = 'extend';
        } else if (videoElement.generatedFrom?.type === 'reshoot') {
          console.warn('âš ï¸ Reshoot è§†é¢‘ä¸åº”è¯¥é€šè¿‡ maybeStartVideo ç”Ÿæˆ');
          return;
        } else if (hasAtLeastOneImage) {
          // è¡Œçº§æ³¨é‡Šï¼šå›¾ç”Ÿè§†é¢‘ - ä½¿ç”¨é¦–å°¾å¸§
          const actualStartId = startImageId || endImageId!;
          const actualEndId = startImageId && endImageId ? endImageId : undefined;

          result = await generateVideoFromImages(actualStartId, actualEndId, promptText);

          if (startImageId) combinedSourceIds.add(startImageId);
          if (endImageId) combinedSourceIds.add(endImageId);
          generationType = 'image-to-image';
        } else {
          // è¡Œçº§æ³¨é‡Šï¼šçº¯æ–‡æœ¬ç”Ÿæˆè§†é¢‘
          const aspectRatio = videoElement.size?.width && videoElement.size?.height
            ? detectAspectRatio(videoElement.size.width, videoElement.size.height)
            : '9:16';

          console.log('ğŸ¬ è°ƒç”¨æ–‡ç”Ÿè§†é¢‘:', { promptText, aspectRatio });
          result = await generateVideoFromText(promptText || '', aspectRatio as '16:9' | '9:16' | '1:1');
          generationType = 'text-to-video';
        }

        // è¡Œçº§æ³¨é‡Šï¼šæ›´æ–°æˆåŠŸçŠ¶æ€
        updateElement(videoId, {
          status: 'ready',
          src: result.videoUrl,
          thumbnail: result.thumbnail,
          duration: result.duration,
          mediaGenerationId: result.mediaGenerationId,
          progress: 100,
          readyForGeneration: true,
          generatedFrom: {
            type: generationType,
            sourceIds: Array.from(combinedSourceIds),
            prompt: promptText,
          },
        } as Partial<VideoElement>);

        // è¡Œçº§æ³¨é‡Šï¼šç§»é™¤è¾¹ç¼˜åŠ¨ç”»
        setEdges((eds: any[]) =>
          eds.map((edge: any) =>
            edge.target === videoId
              ? { ...edge, animated: false, style: EDGE_DEFAULT_STYLE }
              : edge
          )
        );
      } catch (error) {
        console.error('âŒ è§†é¢‘ç”Ÿæˆå¤±è´¥:', error);
        updateElement(videoId, {
          status: 'error',
          readyForGeneration: true,
        } as Partial<VideoElement>);

        // è¡Œçº§æ³¨é‡Šï¼šé”™è¯¯è¾¹ç¼˜æ ·å¼
        setEdges((eds: any[]) =>
          eds.map((edge: any) =>
            edge.target === videoId
              ? { ...edge, animated: false, style: EDGE_ERROR_STYLE }
              : edge
          )
        );
      } finally {
        activeGenerationRef.current.delete(videoId);
      }
    },
    [setEdges, updateElement, addElement]
  );

  return {
    maybeStartVideo,
    activeGenerationRef,
  };
}

