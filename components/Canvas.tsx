'use client';

import { useCallback, useMemo, useEffect, useState, useRef } from 'react';
import {
  ReactFlow,
  ReactFlowProvider,
  Node,
  Edge,
  Controls,
  Background,
  BackgroundVariant,
  useNodesState,
  useEdgesState,
  NodeTypes,
  SelectionMode,
  OnSelectionChangeParams,
  ConnectionLineType,
  OnConnectStart,
  OnConnectEnd,
  useReactFlow,
  type Connection,
} from '@xyflow/react';
import '@xyflow/react/dist/style.css';

import { useCanvasStore } from '@/lib/store';
import ImageNode from './nodes/ImageNode';
import TextNode from './nodes/TextNode';
import VideoNode from './nodes/VideoNode';
import CanvasNavigation from './CanvasNavigation';
import RightToolbar from './RightToolbar';
import AIInputPanel from './AIInputPanel';
import Toolbar from './Toolbar';
import SelectionToolbar from './SelectionToolbar';
import ConnectionMenuRoot from './canvas/connection-menu/ConnectionMenuRoot';
import ImageAnnotatorModal, { ImageAnnotatorResult } from './ImageAnnotatorModal';
import { CanvasElement, VideoElement, ImageElement, TextElement } from '@/lib/types';
import { generateVideoFromText, generateVideoFromImages, generateImage, imageToImage, registerUploadedImage } from '@/lib/api-mock';
import { loadMaterialsFromProject } from '@/lib/project-materials';
import {
  getPositionAboveInput,
  generateFromInput,
  imageToImageFromInput,
  multiImageRecipeFromInput,
} from '@/lib/input-panel-generator';
import { useConnectionMenu } from '@/hooks/canvas/useConnectionMenu';
import { ConnectionMenuCallbacks } from '@/types/connection-menu';
import { useTextToImage } from '@/hooks/canvas/useTextToImage';
import { useImageToImage } from '@/hooks/canvas/useImageToImage';
import { ImageAspectRatio } from '@/types/image-generation';

// æ³¨å†Œè‡ªå®šä¹‰èŠ‚ç‚¹ç±»å‹
const nodeTypes: NodeTypes = {
  image: ImageNode,
  text: TextNode,
  video: VideoNode,
};

const VIDEO_NODE_DEFAULT_SIZE = { width: 400, height: 300 };
const EDGE_DEFAULT_STYLE = { stroke: '#64748b', strokeWidth: 1 };

function CanvasContent({ projectId }: { projectId?: string }) {
  const elements = useCanvasStore((state) => state.elements);
  const updateElement = useCanvasStore((state) => state.updateElement);
  const addElement = useCanvasStore((state) => state.addElement);
  const setSelection = useCanvasStore((state) => state.setSelection);
  const uiState = useCanvasStore((state) => state.uiState);
  const loadProjectPrefixPrompt = useCanvasStore((state) => state.loadProjectPrefixPrompt);

  // å›¾ç‰‡ç¼–è¾‘å™¨çŠ¶æ€ - ä½¿ç”¨å“åº”å¼ hooks
  const annotatorTarget = useCanvasStore((state) => state.annotatorTarget);
  const isLoadingAnnotatorImage = useCanvasStore((state) => state.isLoadingAnnotatorImage);
  const setAnnotatorTarget = useCanvasStore((state) => state.setAnnotatorTarget);
  const setIsLoadingAnnotatorImage = useCanvasStore((state) => state.setIsLoadingAnnotatorImage);
  
  // è¡Œçº§æ³¨é‡Šï¼šå¤šå›¾ç¼–è¾‘ - ä¸»å›¾å’Œå‚è€ƒå›¾
  const [mainImageForEdit, setMainImageForEdit] = useState<ImageElement | null>(null);
  const [referenceImages, setReferenceImages] = useState<ImageElement[]>([]);

  // è¡Œçº§æ³¨é‡Šï¼šReact Flow èŠ‚ç‚¹å’Œè¾¹ç¼˜çŠ¶æ€ï¼ˆéœ€è¦åœ¨ Hooks ä¹‹å‰å£°æ˜ï¼‰
  const [reactFlowNodes, setNodes, onNodesChange] = useNodesState(elements.map(el => ({
    id: el.id,
    type: el.type,
    position: el.position,
    data: el as any,
    draggable: true,
    style: el.size ? {
      width: el.size.width,
      height: el.size.height,
    } : undefined,
  })));
  const [edges, setEdges, onEdgesChange] = useEdgesState<Edge>([]);

  const reactFlowInstance = useReactFlow();

  // è¡Œçº§æ³¨é‡Šï¼šä½¿ç”¨è¿çº¿èœå• Hook ç®¡ç†èœå•çŠ¶æ€
  const {
    connectionMenu,
    promptMenuInputRef,
    resetConnectionMenu,
    showConnectionMenu,
    showImageSubmenu,
    showVideoSubmenu,
    showImagePromptInput,
    updateImagePrompt,
    backToMain,
    backToImageSubmenu,
    prepareConnectionMenu,
  } = useConnectionMenu();

  // è¡Œçº§æ³¨é‡Šï¼šä½¿ç”¨å›¾ç‰‡ç”Ÿæˆ Hooks
  const { handleTextToImage } = useTextToImage({
    addElement,
    updateElement,
    setEdges,
    resetConnectionMenu,
  });

  const { handleImageToImage } = useImageToImage({
    addElement,
    setEdges,
    resetConnectionMenu,
  });

  // è¡Œçº§æ³¨é‡Šï¼šåŒæ­¥ elements åˆ° React Flow èŠ‚ç‚¹çŠ¶æ€ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼šåªåœ¨å…ƒç´ æ•°é‡æˆ– ID å˜åŒ–æ—¶å®Œå…¨é‡å»ºï¼‰
  const elementsIdsRef = useRef<string>('');
  const previousElementsRef = useRef<CanvasElement[]>(elements);
  
  useEffect(() => {
    const newIdsString = elements.map(el => el.id).sort().join(',');
    
    // è¡Œçº§æ³¨é‡Šï¼šåªæœ‰å…ƒç´ æ•°é‡/ID å˜åŒ–æ—¶æ‰å®Œå…¨é‡å»ºèŠ‚ç‚¹åˆ—è¡¨ï¼ˆæ–°å¢/åˆ é™¤èŠ‚ç‚¹ï¼‰
    if (elementsIdsRef.current !== newIdsString) {
      elementsIdsRef.current = newIdsString;
      setNodes(elements.map(el => ({
        id: el.id,
        type: el.type,
        position: el.position,
        data: el as any,
        draggable: true,
        style: el.size ? {
          width: el.size.width,
          height: el.size.height,
        } : undefined,
      })));
      previousElementsRef.current = elements;
    } else {
      // è¡Œçº§æ³¨é‡Šï¼šå…ƒç´ æ•°é‡ä¸å˜æ—¶ï¼Œåªæ›´æ–°èŠ‚ç‚¹çš„ data å’Œ styleï¼ˆé¿å…é‡å»ºæ•´ä¸ªåˆ—è¡¨ï¼‰
      setNodes((currentNodes) =>
        currentNodes.map((node) => {
          const element = elements.find((el) => el.id === node.id);
          const prevElement = previousElementsRef.current.find((el) => el.id === node.id);
          if (!element) return node;
          
          // è¡Œçº§æ³¨é‡Šï¼šæ£€æŸ¥ position æ˜¯å¦çœŸçš„å˜åŒ–äº†ï¼Œé¿å…ä¸å¿…è¦çš„ä½ç½®æ›´æ–°ï¼ˆä¿®å¤è§†é¢‘ç”Ÿæˆæ—¶çš„è·³åŠ¨é—®é¢˜ï¼‰
          const positionChanged = !prevElement || 
            prevElement.position.x !== element.position.x || 
            prevElement.position.y !== element.position.y;
          
          return {
            ...node,
            data: element as any,
            // è¡Œçº§æ³¨é‡Šï¼šåªåœ¨ä½ç½®çœŸçš„å˜åŒ–æ—¶æ‰æ›´æ–° positionï¼Œå¦åˆ™ä¿æŒ React Flow å†…éƒ¨çš„ä½ç½®ä¸å˜
            position: positionChanged ? element.position : node.position,
            style: element.size ? {
              width: element.size.width,
              height: element.size.height,
            } : undefined,
          };
        })
      );
      previousElementsRef.current = elements;
    }
  }, [elements, setNodes]);

  useEffect(() => {
    if (!projectId) {
      return;
    }
    // è®¾ç½® projectId åˆ° store çš„ apiConfig ä¸­
    useCanvasStore.setState((state) => ({
      apiConfig: {
        ...state.apiConfig,
        projectId,
      },
    }));
    // åŠ è½½é¡¹ç›®çš„å‰ç½®æç¤ºè¯
    loadProjectPrefixPrompt(projectId);
    // è¡Œçº§æ³¨é‡Šï¼šç´ æåº“æ”¹ä¸ºæ‰‹åŠ¨åŠ è½½ï¼Œä¸è‡ªåŠ¨åŠ è½½
  }, [projectId, loadProjectPrefixPrompt]);

  const reactFlowWrapperRef = useRef<HTMLDivElement | null>(null);
  const connectionStartRef = useRef<{
    sourceId: string;
    sourceType: CanvasElement['type'];
    handleId?: string | null;
    didConnect: boolean;
  } | null>(null);
  const activeGenerationRef = useRef<Set<string>>(new Set());

  const maybeStartVideo = useCallback(
    async (videoId: string) => {
      if (activeGenerationRef.current.has(videoId)) {
        return;
      }

      const { elements: storeElements } = useCanvasStore.getState();
      const videoElement = storeElements.find((el) => el.id === videoId) as VideoElement | undefined;

      if (!videoElement) return;

      if (videoElement.status !== 'queued') {
        return;
      }

      const promptText = videoElement.promptText?.trim();
      const startImageId = videoElement.startImageId;
      const endImageId = videoElement.endImageId;
      const generationCount = videoElement.generationCount || 1; // è¡Œçº§æ³¨é‡Šï¼šè·å–ç”Ÿæˆæ•°é‡

      const hasAtLeastOneImage = Boolean(startImageId || endImageId);
      // è¡Œçº§æ³¨é‡Šï¼šæ”¯æŒçº¯æ–‡æœ¬ç”Ÿæˆè§†é¢‘ - åªè¦æœ‰æç¤ºè¯å°±å¯ä»¥ç”Ÿæˆ
      const ready = Boolean(promptText);

      if (!ready) {
        updateElement(videoId, {
          status: 'pending',
          readyForGeneration: ready,
        } as Partial<VideoElement>);
        return;
      }

      console.log('ğŸ¬ maybeStartVideo: å¼€å§‹ç”Ÿæˆè§†é¢‘', { videoId, generationCount, promptText });

      // è¡Œçº§æ³¨é‡Šï¼šå¦‚æœ generationCount > 1ï¼Œåˆ›å»ºé¢å¤–çš„è§†é¢‘èŠ‚ç‚¹
      if (generationCount > 1) {
        const basePosition = videoElement.position;
        const size = videoElement.size || { width: 640, height: 360 };
        const spacing = 50; // è¡Œçº§æ³¨é‡Šï¼šèŠ‚ç‚¹ä¹‹é—´çš„é—´è·

        for (let i = 1; i < generationCount; i++) {
          const newVideoId = `video-${Date.now()}-${i}`;
          const newPosition = {
            x: basePosition.x + (size.width + spacing) * i,
            y: basePosition.y,
          };

          const newVideo: VideoElement = {
            id: newVideoId,
            type: 'video',
            src: '',
            thumbnail: '',
            duration: 0,
            status: 'queued',
            progress: 0,
            position: newPosition,
            size: size,
            promptText: promptText,
            startImageId: startImageId,
            endImageId: endImageId,
            generationCount: 1, // è¡Œçº§æ³¨é‡Šï¼šæ¯ä¸ªèŠ‚ç‚¹åªç”Ÿæˆä¸€ä¸ªè§†é¢‘
            generatedFrom: videoElement.generatedFrom,
          };

          const addElement = useCanvasStore.getState().addElement;
          addElement(newVideo);

          // è¡Œçº§æ³¨é‡Šï¼šåˆ›å»ºè¿çº¿åˆ°å›¾ç‰‡èŠ‚ç‚¹
          if (startImageId) {
            const edgeId = `edge-${startImageId}-${newVideoId}-start`;
            setEdges((eds: any[]) => [
              ...eds,
              {
                id: edgeId,
                source: startImageId,
                sourceHandle: null,
                target: newVideoId,
                targetHandle: 'start-image',
                type: 'default',
                animated: true,
                style: { stroke: '#3b82f6', strokeWidth: 2 },
              },
            ]);
          }
          if (endImageId && endImageId !== startImageId) {
            const edgeId = `edge-${endImageId}-${newVideoId}-end`;
            setEdges((eds: any[]) => [
              ...eds,
              {
                id: edgeId,
                source: endImageId,
                sourceHandle: null,
                target: newVideoId,
                targetHandle: 'end-image',
                type: 'default',
                animated: true,
                style: { stroke: '#3b82f6', strokeWidth: 2 },
              },
            ]);
          }

          console.log('âœ… åˆ›å»ºé¢å¤–è§†é¢‘èŠ‚ç‚¹:', newVideoId);

          // è¡Œçº§æ³¨é‡Šï¼šå»¶è¿Ÿè§¦å‘ç”Ÿæˆï¼Œé¿å…åŒæ—¶å‘èµ·å¤ªå¤šè¯·æ±‚
          setTimeout(() => {
            maybeStartVideo(newVideoId);
          }, i * 500); // æ¯ä¸ªè§†é¢‘é—´éš” 0.5 ç§’
        }
      }

      activeGenerationRef.current.add(videoId);

      updateElement(videoId, {
        status: 'generating',
        readyForGeneration: true,
        src: '',
        thumbnail: '',
      } as Partial<VideoElement>);

      // @ts-ignore
      setEdges((eds: any[]) =>
        eds.map((edge: any) =>
          edge.target === videoId
            ? {
              ...edge,
              animated: true,
              style: { stroke: '#a855f7', strokeWidth: 1 },
            }
            : edge
        )
      );

      try {
        let result;
        let generationType: 'text-to-video' | 'image-to-image' = 'text-to-video';
        const combinedSourceIds = new Set<string>(videoElement.generatedFrom?.sourceIds ?? []);

        // è¡Œçº§æ³¨é‡Šï¼šåˆ¤æ–­æ˜¯å›¾ç”Ÿè§†é¢‘è¿˜æ˜¯æ–‡ç”Ÿè§†é¢‘
        if (hasAtLeastOneImage) {
          // è¡Œçº§æ³¨é‡Šï¼šå›¾ç”Ÿè§†é¢‘ - ä½¿ç”¨é¦–å°¾å¸§
          const actualStartId = startImageId || endImageId!;
          const actualEndId = startImageId && endImageId ? endImageId : undefined;

          result = await generateVideoFromImages(actualStartId, actualEndId, promptText);
          
          if (startImageId) combinedSourceIds.add(startImageId);
          if (endImageId) combinedSourceIds.add(endImageId);
          generationType = 'image-to-image';
        } else {
          // è¡Œçº§æ³¨é‡Šï¼šçº¯æ–‡æœ¬ç”Ÿæˆè§†é¢‘
          const aspectRatio = videoElement.size?.width && videoElement.size?.height 
            ? (Math.abs(videoElement.size.width / videoElement.size.height - 16/9) < 0.1 ? '16:9'
              : Math.abs(videoElement.size.width / videoElement.size.height - 9/16) < 0.1 ? '9:16'
              : '1:1')
            : '9:16'; // è¡Œçº§æ³¨é‡Šï¼šé»˜è®¤ç«–å±ï¼ˆä¸ Google å®˜æ–¹é»˜è®¤ä¸€è‡´ï¼‰
          
          console.log('ğŸ¬ è°ƒç”¨æ–‡ç”Ÿè§†é¢‘:', { promptText, aspectRatio });
          result = await generateVideoFromText(promptText || '', aspectRatio as '16:9' | '9:16' | '1:1');
          generationType = 'text-to-video';
        }

        updateElement(videoId, {
          status: 'ready',
          src: result.videoUrl,
          thumbnail: result.thumbnail,
          duration: result.duration,
          mediaGenerationId: result.mediaGenerationId,
          progress: 100,
          readyForGeneration: true,
          generatedFrom: {
            type: generationType,
            sourceIds: Array.from(combinedSourceIds),
            prompt: promptText,
          },
        } as Partial<VideoElement>);

        // @ts-ignore
        setEdges((eds: any[]) =>
          eds.map((edge: any) =>
            edge.target === videoId
              ? {
                ...edge,
                animated: false,
                style: EDGE_DEFAULT_STYLE,
              }
              : edge
          )
        );
      } catch (error) {
        console.error('âŒ å›¾ç”Ÿè§†é¢‘ç”Ÿæˆå¤±è´¥:', error);
        updateElement(videoId, {
          status: 'error',
          readyForGeneration: true,
        } as Partial<VideoElement>);

        // @ts-ignore
        setEdges((eds: any[]) =>
          eds.map((edge: any) =>
            edge.target === videoId
              ? {
                ...edge,
                animated: false,
                style: { stroke: '#ef4444', strokeWidth: 1 },
              }
              : edge
          )
        );
      } finally {
        activeGenerationRef.current.delete(videoId);
      }
    },
    [setEdges, updateElement]
  );

  useEffect(() => {
    useCanvasStore.setState({
      triggerVideoGeneration: (videoId: string) => {
        void maybeStartVideo(videoId);
      },
    });
    return () => {
      useCanvasStore.setState({ triggerVideoGeneration: undefined });
    };
  }, [maybeStartVideo]);

  // è¡Œçº§æ³¨é‡Šï¼šæ³¨å†Œä»è¾“å…¥æ¡†ç”Ÿæˆå›¾ç‰‡çš„å›è°ƒ
  const handleGenerateFromInput = useCallback(
    async (
      prompt: string,
      aspectRatio: '16:9' | '9:16' | '1:1',
      count: number,
      panelRef: HTMLDivElement | null
    ) => {
      const { elements: storeElements, selection, addPromptHistory } = useCanvasStore.getState();
      const position = getPositionAboveInput(panelRef, reactFlowInstance.screenToFlowPosition);

      // è¡Œçº§æ³¨é‡Šï¼šè·å–é€‰ä¸­çš„å›¾ç‰‡
      const selectedImages = storeElements
        .filter((el) => selection.includes(el.id) && el.type === 'image')
        .map((el) => el as ImageElement);

      try {
        if (selectedImages.length === 0) {
          // è¡Œçº§æ³¨é‡Šï¼šæ–‡ç”Ÿå›¾
          await generateFromInput(
            prompt,
            aspectRatio,
            count,
            position,
            addElement,
            updateElement,
            useCanvasStore.getState().deleteElement,
            addPromptHistory
          );
        } else if (selectedImages.length === 1) {
          // è¡Œçº§æ³¨é‡Šï¼šå›¾ç”Ÿå›¾
          await imageToImageFromInput(
            prompt,
            aspectRatio,
            count,
            selectedImages[0],
            addElement,
            updateElement,
            useCanvasStore.getState().deleteElement,
            addPromptHistory,
            setEdges
          );
        } else {
          // è¡Œçº§æ³¨é‡Šï¼šå¤šå›¾èåˆ
          await multiImageRecipeFromInput(
            prompt,
            aspectRatio,
            count,
            selectedImages,
            addElement,
            updateElement,
            useCanvasStore.getState().deleteElement,
            addPromptHistory,
            setEdges
          );
        }
      } catch (error: any) {
        console.error('ç”Ÿæˆå¤±è´¥:', error);
      }
    },
    [addElement, updateElement, setEdges, reactFlowInstance]
  );

  useEffect(() => {
    useCanvasStore.setState({
      onGenerateFromInput: handleGenerateFromInput,
    });
    return () => {
      useCanvasStore.setState({ onGenerateFromInput: undefined });
    };
  }, [handleGenerateFromInput]);

  const createVideoNodeFromImage = useCallback(
    (
      imageNode: ImageElement,
      flowPosition: { x: number; y: number },
      targetHandleId: 'start-image' | 'end-image' = 'start-image',
      sourceHandleId?: string | null
    ) => {
      const videoId = `video-${Date.now()}`;
      const baseSize = imageNode.size && imageNode.size.width && imageNode.size.height
        ? imageNode.size
        : VIDEO_NODE_DEFAULT_SIZE;

      const nextVideoSize = {
        width: baseSize.width,
        height: baseSize.height,
      };

      const position = {
        x: flowPosition.x - nextVideoSize.width / 2,
        y: flowPosition.y - nextVideoSize.height / 2,
      };

      const startImageInfo =
        targetHandleId === 'start-image'
          ? { startImageId: imageNode.id, startImageUrl: imageNode.src }
          : {};
      const endImageInfo =
        targetHandleId === 'end-image'
          ? { endImageId: imageNode.id, endImageUrl: imageNode.src }
          : {};

      const newVideo: VideoElement = {
        id: videoId,
        type: 'video',
        src: '',
        thumbnail: '',
        duration: 0,
        status: 'pending',
        progress: 0,
        position,
        size: { ...nextVideoSize },
        readyForGeneration: false,
        ...startImageInfo,
        ...endImageInfo,
      };

      addElement(newVideo);

      const edgeId = `edge-${imageNode.id}-${videoId}-${targetHandleId}`;
      // @ts-ignore
      setEdges((eds: any[]) => {
        const filtered = (eds as any[]).filter((edge: any) => edge.id !== edgeId);
        return [
          ...filtered,
          {
            id: edgeId,
            source: imageNode.id,
            target: videoId,
            sourceHandle: sourceHandleId ?? undefined,
            targetHandle: targetHandleId,
            type: 'default',
            animated: false,
            style: EDGE_DEFAULT_STYLE,
          },
        ];
      });
    },
    [addElement, setEdges]
  );

  const createTextNodeForVideo = useCallback(
    (videoNode: VideoElement, flowPosition: { x: number; y: number }) => {
      const textId = `text-${Date.now()}`;
      const textContent = videoNode.promptText || 'åŒå‡»ç¼–è¾‘æ–‡å­—';

      // æ ¹æ®æ–‡å­—å†…å®¹è®¡ç®—èŠ‚ç‚¹å°ºå¯¸
      const fontSize = 24;
      const tempDiv = document.createElement('div');
      tempDiv.style.position = 'absolute';
      tempDiv.style.visibility = 'hidden';
      tempDiv.style.fontSize = `${fontSize}px`;
      tempDiv.style.fontWeight = 'normal';
      tempDiv.style.whiteSpace = 'pre-wrap';
      tempDiv.style.lineHeight = '1.4';
      tempDiv.style.maxWidth = '600px';
      tempDiv.textContent = textContent;

      document.body.appendChild(tempDiv);
      const width = Math.ceil(tempDiv.offsetWidth);
      const height = Math.ceil(tempDiv.offsetHeight);
      document.body.removeChild(tempDiv);

      // æ·»åŠ å†…è¾¹è·
      const padding = 24;
      const calculatedSize = {
        width: Math.max(100, Math.min(600, width + padding * 2)),
        height: Math.max(60, Math.min(400, height + padding * 2)),
      };

      const position = {
        x: flowPosition.x - calculatedSize.width / 2,
        y: flowPosition.y - calculatedSize.height / 2,
      };

      const newText: TextElement = {
        id: textId,
        type: 'text',
        text: textContent,
        position,
        size: calculatedSize,
        fontSize,
      };

      addElement(newText);

      const edgeId = `edge-${textId}-${videoNode.id}-prompt-text`;
      // @ts-ignore
      setEdges((eds: any[]) => {
        const filtered = (eds as any[]).filter((edge: any) => edge.id !== edgeId);
        return [
          ...filtered,
          {
            id: edgeId,
            source: textId,
            target: videoNode.id,
            targetHandle: 'prompt-text',
            type: 'default',
            animated: false,
            style: EDGE_DEFAULT_STYLE,
          },
        ];
      });

      const promptText = videoNode.promptText ?? '';
      const sourceIds = new Set<string>(videoNode.generatedFrom?.sourceIds ?? []);
      if (videoNode.startImageId) {
        sourceIds.add(videoNode.startImageId);
      }
      if (videoNode.endImageId) {
        sourceIds.add(videoNode.endImageId);
      }
      sourceIds.add(textId);

      updateElement(videoNode.id, {
        promptText,
        readyForGeneration: Boolean(promptText.trim() && (videoNode.startImageId || videoNode.endImageId)),
        generatedFrom: {
          type: 'image-to-image',
          sourceIds: Array.from(sourceIds),
          prompt: promptText,
        },
      } as Partial<VideoElement>);
    },
    [addElement, setEdges, updateElement]
  );

  // è¡Œçº§æ³¨é‡Šï¼šå°† store ä¸­çš„å…ƒç´ è½¬æ¢ä¸º React Flow èŠ‚ç‚¹
  // @ts-ignore - React Flow ç±»å‹æ¨æ–­é—®é¢˜
  const nodes: Node[] = useMemo(() => {
    return elements.map((el: CanvasElement) => ({
      id: el.id,
      type: el.type,
      position: el.position,
      data: el,
      draggable: true,
      style: el.size ? {
        width: el.size.width,
        height: el.size.height,
      } : undefined,
    }));
  }, [elements]);

  // è¡Œçº§æ³¨é‡Šï¼šç§»é™¤æ­¤ useEffectï¼Œé¿å…é‡å¤æ¸²æŸ“ï¼ˆå·²ç»åœ¨ä¸Šé¢çš„ useEffect ä¸­å¤„ç†äº†èŠ‚ç‚¹åŒæ­¥ï¼‰

  // è¡Œçº§æ³¨é‡Šï¼šç§»é™¤æŒ‡å‘å·²åˆ é™¤èŠ‚ç‚¹çš„è¿çº¿
  useEffect(() => {
    // @ts-ignore
    setEdges((currentEdges: any[]) =>
      currentEdges.filter((edge: any) => {
        const sourceExists = elements.some((el) => el.id === edge.source);
        const targetExists = elements.some((el) => el.id === edge.target);
        return sourceExists && targetExists;
      })
    );
  }, [elements, setEdges]);

  // æ‹¦æˆª onNodesChangeï¼Œå¤„ç†åˆ é™¤äº‹ä»¶å¹¶åŒæ­¥åˆ° store
  const handleNodesChange = useCallback(
    (changes: any[]) => {
      // è¡Œçº§æ³¨é‡Šï¼šè¿‡æ»¤æ‰æ­£åœ¨ç”Ÿæˆ/å¤„ç†ä¸­çš„èŠ‚ç‚¹åˆ é™¤æ“ä½œ
      const filteredChanges = changes.filter((change) => {
        if (change.type === 'remove') {
          const element = elements.find((el) => el.id === change.id);
          
          if (element) {
            // è¡Œçº§æ³¨é‡Šï¼šæ£€æŸ¥è§†é¢‘èŠ‚ç‚¹æ˜¯å¦æ­£åœ¨ç”Ÿæˆ
            if (element.type === 'video') {
              const videoElement = element as VideoElement;
              if (videoElement.status === 'queued' || videoElement.status === 'generating') {
                alert('è§†é¢‘æ­£åœ¨ç”Ÿæˆä¸­ï¼Œæ— æ³•åˆ é™¤');
                return false; // é˜»æ­¢åˆ é™¤
              }
            }
            
            // è¡Œçº§æ³¨é‡Šï¼šæ£€æŸ¥å›¾ç‰‡èŠ‚ç‚¹æ˜¯å¦æ­£åœ¨å¤„ç†
            if (element.type === 'image') {
              const imageElement = element as ImageElement;
              const isSyncing = imageElement.uploadState === 'syncing';
              const hasMediaId = Boolean(imageElement.mediaGenerationId);
              const isError = imageElement.uploadState === 'error';
              const isProcessing = !isError && (isSyncing || !hasMediaId);
              
              if (isProcessing) {
                alert('å›¾ç‰‡æ­£åœ¨ç”Ÿæˆ/å¤„ç†ä¸­ï¼Œæ— æ³•åˆ é™¤');
                return false; // é˜»æ­¢åˆ é™¤
              }
            }
          }
          
          // è¡Œçº§æ³¨é‡Šï¼šå…è®¸åˆ é™¤ï¼Œä» store ä¸­åˆ é™¤å…ƒç´ 
          useCanvasStore.getState().deleteElement(change.id);
        }
        
        return true; // ä¿ç•™è¿™ä¸ªå˜åŒ–
      });

      // è¡Œçº§æ³¨é‡Šï¼šä¼ é€’è¿‡æ»¤åçš„å˜åŒ–ç»™ React Flow
      onNodesChange(filteredChanges);
    },
    [onNodesChange, elements]
  );

  // è¡Œçº§æ³¨é‡Šï¼šæ‹–åŠ¨è¿‡ç¨‹ä¸­çš„èŠ‚ç‚¹ä½ç½®ç¼“å­˜ï¼ˆé¿å…é¢‘ç¹æ›´æ–° storeï¼‰
  const draggedNodesRef = useRef<Map<string, { x: number; y: number }>>(new Map());
  
  // è¡Œçº§æ³¨é‡Šï¼šæ‹–åŠ¨è¿‡ç¨‹ä¸­åªæ›´æ–°æœ¬åœ°çŠ¶æ€ï¼Œä¸è§¦å‘ store æ›´æ–°ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
  const handleNodeDrag = useCallback(
    (_event: React.MouseEvent, node: Node) => {
      draggedNodesRef.current.set(node.id, { x: node.position.x, y: node.position.y });
    },
    []
  );

  // è¡Œçº§æ³¨é‡Šï¼šæ‹–åŠ¨ç»“æŸåæ‰¹é‡æ›´æ–° storeï¼ˆå‡å°‘æ¸²æŸ“æ¬¡æ•°ï¼‰
  const handleNodeDragStop = useCallback(
    (_event: React.MouseEvent, node: Node, nodes: Node[]) => {
      // æ‰¾åˆ°æ‰€æœ‰è¢«æ‹–åŠ¨çš„èŠ‚ç‚¹ï¼ˆåŒ…æ‹¬å¤šé€‰ï¼‰
      const selectedNodes = nodes.filter(n => n.selected);
      const nodesToUpdate = selectedNodes.length > 1 ? selectedNodes : [node];

      // è¡Œçº§æ³¨é‡Šï¼šæ‰¹é‡æ›´æ–°ä½ç½®åˆ° storeï¼ˆä¸€æ¬¡æ€§æ›´æ–°ï¼Œé¿å…å¤šæ¬¡è§¦å‘ elements å˜åŒ–ï¼‰
      const { elements: currentElements } = useCanvasStore.getState();
      const updatedElements = currentElements.map((el) => {
        const draggedNode = nodesToUpdate.find((n) => n.id === el.id);
        if (draggedNode) {
          return { ...el, position: draggedNode.position };
        }
        return el;
      });
      
      // è¡Œçº§æ³¨é‡Šï¼šç›´æ¥æ›¿æ¢æ•´ä¸ª elements æ•°ç»„ï¼ˆä¸€æ¬¡æ€§æ›´æ–°ï¼Œè€Œéå¤šæ¬¡è°ƒç”¨ updateElementï¼‰
      useCanvasStore.setState({ elements: updatedElements });
      
      // æ¸…ç©ºæ‹–åŠ¨ç¼“å­˜
      draggedNodesRef.current.clear();
    },
    []
  );

  // å¤„ç†é€‰ä¸­å˜åŒ–
  const handleSelectionChange = useCallback(
    (params: OnSelectionChangeParams) => {
      const selectedIds = params.nodes.map((node) => node.id);
      setSelection(selectedIds);
    },
    [setSelection]
  );

  // å¤„ç†è¿çº¿å¼€å§‹ - è®°å½•æºèŠ‚ç‚¹ä¿¡æ¯
  const handleConnectStart = useCallback<OnConnectStart>(
    (_event, params) => {
      const sourceNode = elements.find((el) => el.id === params.nodeId);

      if (!sourceNode) {
        connectionStartRef.current = null;
        resetConnectionMenu();
        return;
      }

      connectionStartRef.current = {
        sourceId: sourceNode.id,
        sourceType: sourceNode.type,
        handleId: params.handleId,
        didConnect: false,
      };

      prepareConnectionMenu(sourceNode.id, sourceNode.type as CanvasElement['type']);
    },
    [elements, prepareConnectionMenu, resetConnectionMenu]
  );

  // å¤„ç†è¿çº¿ç»“æŸ - æ˜¾ç¤ºé€‰é¡¹èœå•
  const handleConnectEnd = useCallback<OnConnectEnd>(
    (event) => {
      const startInfo = connectionStartRef.current;
      connectionStartRef.current = null;

      const mouseEvent = event as MouseEvent;
      const targetElement = mouseEvent?.target as HTMLElement | null;
      const droppedOnPane = targetElement?.classList?.contains('react-flow__pane');

      if (!startInfo) {
        resetConnectionMenu();
        return;
      }

      if (startInfo.didConnect) {
        resetConnectionMenu();
        return;
      }

      if (!droppedOnPane) {
        resetConnectionMenu();
        return;
      }

      if (startInfo.sourceType === 'text') {
        const sourceNode = elements.find((el) => el.id === startInfo.sourceId);
        if (!sourceNode || sourceNode.type !== 'text') {
          resetConnectionMenu();
          return;
        }

        showConnectionMenu(
          { x: mouseEvent.clientX, y: mouseEvent.clientY },
          sourceNode.id,
          'text'
        );
        return;
      }

      if (startInfo.sourceType === 'video' && startInfo.handleId === 'prompt-text') {
        const videoNode = elements.find((el) => el.id === startInfo.sourceId) as VideoElement | undefined;
        if (!videoNode) {
          resetConnectionMenu();
          return;
        }

        const flowPosition = reactFlowInstance.screenToFlowPosition({
          x: mouseEvent.clientX,
          y: mouseEvent.clientY,
        });

        createTextNodeForVideo(videoNode, flowPosition);
        resetConnectionMenu();
        return;
      }

      if (startInfo.sourceType === 'image') {
        const sourceNode = elements.find((el) => el.id === startInfo.sourceId) as ImageElement | undefined;
        if (!sourceNode) {
          resetConnectionMenu();
          return;
        }

        // è¡Œçº§æ³¨é‡Šï¼šå›¾ç‰‡èŠ‚ç‚¹æ‹‰çº¿æ—¶ä¹Ÿæ˜¾ç¤ºèœå•ï¼Œè®©ç”¨æˆ·é€‰æ‹©ç”Ÿæˆå›¾ç‰‡è¿˜æ˜¯è§†é¢‘
        showConnectionMenu(
          { x: mouseEvent.clientX, y: mouseEvent.clientY },
          sourceNode.id,
          'image'
        );
        return;
      }
    },
    [elements, createTextNodeForVideo, reactFlowInstance, resetConnectionMenu, showConnectionMenu]
  );

  // å¤„ç†é€‰æ‹©ç”Ÿæˆå›¾ç‰‡ï¼ˆå¸¦æ¯”ä¾‹å‚æ•°ï¼‰
  const handleGenerateImage = useCallback(
    async (aspectRatio: ImageAspectRatio) => {
      const sourceNodeId = connectionMenu.sourceNodeId;
      const sourceNodeType = connectionMenu.sourceNodeType;
      if (!sourceNodeId || !sourceNodeType) return;

      const sourceNode = elements.find((el) => el.id === sourceNodeId);
      if (!sourceNode) return;

      // è¡Œçº§æ³¨é‡Šï¼šä»æ–‡å­—èŠ‚ç‚¹ç”Ÿæˆå›¾ç‰‡ï¼ˆæ–‡ç”Ÿå›¾ï¼‰
      if (sourceNodeType === 'text' && sourceNode.type === 'text') {
        handleTextToImage(sourceNode as TextElement, aspectRatio);
        return;
      }

      // è¡Œçº§æ³¨é‡Šï¼šä»å›¾ç‰‡èŠ‚ç‚¹ç”Ÿæˆå›¾ç‰‡ï¼ˆå›¾ç”Ÿå›¾ï¼‰
      if (sourceNodeType === 'image' && sourceNode.type === 'image') {
        showImagePromptInput(aspectRatio);
        return;
      }
    },
    [connectionMenu.sourceNodeId, connectionMenu.sourceNodeType, elements, handleTextToImage, showImagePromptInput]
  );

  // è¡Œçº§æ³¨é‡Šï¼šå›¾ç”Ÿå›¾æç¤ºè¯è¾“å…¥å˜åŒ–å¤„ç†ï¼ˆç°åœ¨ç”± Hook ç®¡ç†ï¼‰
  const handleImagePromptInputChange = useCallback(
    (value: string) => {
      updateImagePrompt(value);
    },
    [updateImagePrompt]
  );

  const handleConfirmImagePrompt = useCallback(() => {
    const config = connectionMenu.pendingImageConfig;
    const sourceNodeId = connectionMenu.sourceNodeId;
    if (!config || !sourceNodeId) {
      return;
    }

    const promptText = config.prompt.trim();
    if (!promptText) {
      alert('è¯·è¾“å…¥æç¤ºè¯');
      return;
    }

    const sourceNode = elements.find(
      (el) => el.id === sourceNodeId && el.type === 'image'
    ) as ImageElement | undefined;

    if (!sourceNode) {
      resetConnectionMenu();
      return;
    }

    handleImageToImage(sourceNode, config.aspectRatio, promptText);
  }, [
    connectionMenu.pendingImageConfig,
    connectionMenu.sourceNodeId,
    elements,
    handleImageToImage,
    resetConnectionMenu,
  ]);

  // å¤„ç†é€‰æ‹©ç”Ÿæˆè§†é¢‘
  const handleGenerateVideo = useCallback(
    async (aspectRatio: '9:16' | '16:9') => {
      const sourceNodeId = connectionMenu.sourceNodeId;
      const sourceNodeType = connectionMenu.sourceNodeType;
      if (!sourceNodeId || !sourceNodeType) return;

      const sourceNode = elements.find((el) => el.id === sourceNodeId);
      if (!sourceNode) return;

      // è¡Œçº§æ³¨é‡Šï¼šä»æ–‡å­—èŠ‚ç‚¹ç”Ÿæˆè§†é¢‘
      if (sourceNodeType === 'text' && sourceNode.type === 'text') {
        handleTextToVideo(sourceNode as TextElement, aspectRatio);
        return;
      }

      // è¡Œçº§æ³¨é‡Šï¼šä»å›¾ç‰‡èŠ‚ç‚¹ç”Ÿæˆè§†é¢‘
      if (sourceNodeType === 'image' && sourceNode.type === 'image') {
        handleImageToVideo(sourceNode as ImageElement, aspectRatio);
        return;
      }
    },
    [connectionMenu.sourceNodeId, connectionMenu.sourceNodeType, elements]
  );

  // å›¾ç‰‡ç¼–è¾‘å™¨å›è°ƒå‡½æ•° - ä½¿ç”¨ useCallback é¿å…ä¸å¿…è¦çš„é‡æ–°æ¸²æŸ“
  const handleAnnotatorClose = useCallback(() => {
    setAnnotatorTarget(null);
    setMainImageForEdit(null); // æ¸…ç©ºä¸»å›¾
    setReferenceImages([]); // æ¸…ç©ºå‚è€ƒå›¾
  }, [setAnnotatorTarget]);

  // è¡Œçº§æ³¨é‡Šï¼šå¤šå›¾ç¼–è¾‘ - ç”¨æˆ·ä»ç”»å¸ƒé€‰ä¸­å¤šå¼ å›¾ç‰‡åç‚¹å‡»"å›¾ç‰‡ç¼–è¾‘"
  const handleMultiImageEdit = useCallback(async () => {
    const selection = useCanvasStore.getState().selection;
    const selectedImages = elements
      .filter((el) => selection.includes(el.id) && el.type === 'image')
      .map((el) => el as ImageElement);

    if (selectedImages.length < 2 || selectedImages.length > 6) {
      console.error('å¤šå›¾ç¼–è¾‘éœ€è¦ 2-6 å¼ å›¾ç‰‡');
      return;
    }

    // ç¬¬1å¼ ä½œä¸ºä¸»å›¾ï¼Œå…¶ä»–ä½œä¸ºå‚è€ƒå›¾
    const mainImage = selectedImages[0];
    const refImages = selectedImages.slice(1);

    // åŠ è½½ä¸»å›¾
    setIsLoadingAnnotatorImage(true);

    try {
      const apiConfig = useCanvasStore.getState().apiConfig;
      
      // è¡Œçº§æ³¨é‡Šï¼šå°† API é…ç½®æš´éœ²åˆ° windowï¼Œä¾› ImageAnnotatorModal ä½¿ç”¨
      if (typeof window !== 'undefined') {
        (window as any).__API_KEY__ = apiConfig.apiKey || '';
        (window as any).__PROXY__ = apiConfig.proxy || '';
        (window as any).__BEARER_TOKEN__ = apiConfig.bearerToken || '';
      }
      
      // è¡Œçº§æ³¨é‡Šï¼šåŠ è½½ä¸»å›¾çš„ base64 æ•°æ®
      let mainImageBase64Src: string;
      
      // å¦‚æœä¸»å›¾æœ‰ base64ï¼Œç›´æ¥ä½¿ç”¨
      if (mainImage.base64) {
        mainImageBase64Src = mainImage.base64.startsWith('data:')
          ? mainImage.base64
          : `data:image/png;base64,${mainImage.base64}`;
      } else {
        // å¦‚æœæ²¡æœ‰ base64ï¼Œé€šè¿‡ API è·å–
        const effectiveMediaId = mainImage.mediaId || mainImage.mediaGenerationId;
        
        if (!effectiveMediaId) {
          throw new Error('ä¸»å›¾ç¼ºå°‘ mediaIdï¼Œæ— æ³•ç¼–è¾‘');
        }
        
        if (!apiConfig.bearerToken) {
          throw new Error('è¯·å…ˆåœ¨è®¾ç½®ä¸­é…ç½® Bearer Token');
        }

        const mediaResponse = await fetch(
          `/api/flow/media/${effectiveMediaId}?key=${apiConfig.apiKey}&returnUriOnly=false&proxy=${apiConfig.proxy || ''}`,
          {
            headers: apiConfig.bearerToken ? {
              'Authorization': `Bearer ${apiConfig.bearerToken}`
            } : {}
          }
        );

        if (!mediaResponse.ok) {
          throw new Error('è·å–å›¾ç‰‡å¤±è´¥');
        }

        const mediaData = await mediaResponse.json();
        const encodedImage = mediaData?.image?.encodedImage ||
          mediaData?.userUploadedImage?.image ||
          mediaData?.userUploadedImage?.encodedImage;

        if (!encodedImage) {
          throw new Error('æœªè·å–åˆ°å›¾ç‰‡æ•°æ®');
        }
        
        mainImageBase64Src = encodedImage.startsWith('data:')
          ? encodedImage
          : `data:image/png;base64,${encodedImage}`;
      }
      
      // è¡Œçº§æ³¨é‡Šï¼šç¡®ä¿å‚è€ƒå›¾ä¹ŸåŒ…å« base64ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰ï¼Œç”¨äºåˆ‡æ¢ä¸»å›¾
      const refImagesWithBase64 = refImages.map(img => {
        if (img.base64) {
          const base64Src = img.base64.startsWith('data:')
            ? img.base64
            : `data:image/png;base64,${img.base64}`;
          return { ...img, base64: base64Src };
        }
        return img;
      });

      setAnnotatorTarget({
        ...mainImage,
        src: mainImageBase64Src,
        base64: mainImageBase64Src,
      });
      setMainImageForEdit({
        ...mainImage,
        base64: mainImageBase64Src,
      });
      setReferenceImages(refImagesWithBase64);
      setIsLoadingAnnotatorImage(false);

    } catch (error) {
      console.error('âŒ åŠ è½½ä¸»å›¾å¤±è´¥:', error);
      setAnnotatorTarget(null);
      setMainImageForEdit(null);
      setReferenceImages([]);
      setIsLoadingAnnotatorImage(false);
    }
  }, [elements, setAnnotatorTarget, setIsLoadingAnnotatorImage]);

  const handleAnnotatorConfirm = useCallback(async (
    result: ImageAnnotatorResult, 
    annotatedImageDataUrl: string,
    finalMainImage?: ImageElement,
    finalReferenceImages?: ImageElement[]
  ) => {
    // è¡Œçº§æ³¨é‡Šï¼šä½¿ç”¨ç”¨æˆ·æœ€ç»ˆç¡®è®¤çš„ä¸»å›¾å’Œå‚è€ƒå›¾ï¼ˆå¯èƒ½è¢«åˆ‡æ¢è¿‡ï¼‰
    const currentMainImage = finalMainImage || annotatorTarget;
    const currentReferenceImages = finalReferenceImages || referenceImages;
    
    if (!currentMainImage || !result.promptText?.trim()) return;

    const newImageId = `image-${Date.now()}`;
    const hasReferenceImages = currentReferenceImages.length > 0;
    const allSourceImages = [currentMainImage, ...currentReferenceImages];

    try {
      const aspectRatio = (() => {
        const width = currentMainImage.size?.width || 640;
        const height = currentMainImage.size?.height || 360;
        const ratio = width / height;
        if (Math.abs(ratio - 16 / 9) < 0.1) return '16:9';
        if (Math.abs(ratio - 9 / 16) < 0.1) return '9:16';
        return '1:1';
      })() as '16:9' | '9:16' | '1:1';

      const size = aspectRatio === '9:16' ? { width: 360, height: 640 }
        : aspectRatio === '1:1' ? { width: 512, height: 512 }
          : { width: 640, height: 360 };

      const newImage: ImageElement = {
        id: newImageId,
        type: 'image',
        src: '',
        position: {
          x: currentMainImage.position.x + (currentMainImage.size?.width || 640) + 50,
          y: currentMainImage.position.y,
        },
        size,
        sourceImageIds: allSourceImages.map(img => img.id),
        generatedFrom: {
          type: 'image-to-image',
          sourceIds: allSourceImages.map(img => img.id),
          prompt: result.promptText,
        },
      };

      addElement(newImage);

      // è¡Œçº§æ³¨é‡Šï¼šä¸ºæ‰€æœ‰æºå›¾ç‰‡åˆ›å»ºè¿çº¿ï¼ˆä¸»å›¾ + å‚è€ƒå›¾ï¼‰
      const edgeIds: string[] = [];
      // @ts-ignore
      setEdges((eds: any[]) => {
        const newEdges = allSourceImages.map(sourceImg => {
          const edgeId = `edge-${sourceImg.id}-${newImageId}-edit`;
          edgeIds.push(edgeId);
          return {
            id: edgeId,
            source: sourceImg.id,
            sourceHandle: null,
            target: newImageId,
            targetHandle: null,
            type: 'default',
            animated: true,
            style: { stroke: '#a855f7', strokeWidth: 1 },
          };
        });
        return [...eds, ...newEdges];
      });

      // ä¸Šä¼ æ ‡æ³¨å›¾
      const base64Data = annotatedImageDataUrl.split(',')[1];
      const uploadResult = await registerUploadedImage(base64Data);
      if (!uploadResult.mediaGenerationId) throw new Error('ä¸Šä¼ æ ‡æ³¨å›¾å¤±è´¥');

      let imageResult;

      if (hasReferenceImages) {
        // è¡Œçº§æ³¨é‡Šï¼šå¤šå›¾ç¼–è¾‘ - ä½¿ç”¨ runImageRecipeï¼ˆä¸ä½¿ç”¨å‰ç½®æç¤ºè¯ï¼‰
        console.log('ğŸ§© å¤šå›¾èåˆæ¨¡å¼ï¼Œå‚è€ƒå›¾æ•°é‡:', referenceImages.length);

        const { runImageRecipe } = await import('@/lib/api-mock');

        // æ„å»ºå‚è€ƒå›¾åˆ—è¡¨
        const references = [
          // ä¸»å›¾ï¼ˆæ ‡æ³¨åï¼‰
          {
            mediaId: uploadResult.mediaGenerationId,
          caption: 'æ ‡æ³¨åçš„ä¸»å›¾',
          mediaCategory: 'MEDIA_CATEGORY_BOARD',
        },
        // å‚è€ƒå›¾
        ...currentReferenceImages.map((ref, index) => ({
            mediaId: ref.mediaId || ref.mediaGenerationId,
            caption: ref.caption || `å‚è€ƒå›¾${index + 1}`,
            mediaCategory: 'MEDIA_CATEGORY_SUBJECT',
          }))
        ];

        // æ£€æŸ¥æ‰€æœ‰å›¾ç‰‡æ˜¯å¦æœ‰ mediaId
        for (const ref of references) {
          if (!ref.mediaId) {
            throw new Error('å­˜åœ¨æœªåŒæ­¥åˆ° Flow çš„å‚è€ƒå›¾ï¼Œè¯·ç¨åé‡è¯•');
          }
        }

        imageResult = await runImageRecipe(
          result.promptText,
          references,
          aspectRatio,
          undefined,
          1
        );

      } else {
        // è¡Œçº§æ³¨é‡Šï¼šå•å›¾ç¼–è¾‘ - ä½¿ç”¨ imageToImageï¼ˆä¸ä½¿ç”¨å‰ç½®æç¤ºè¯ï¼‰
        console.log('ğŸ¨ å•å›¾ç¼–è¾‘æ¨¡å¼');

        imageResult = await imageToImage(
          result.promptText,
          annotatedImageDataUrl,
          aspectRatio,
          '',
          uploadResult.mediaGenerationId,
          1
        );
      }

      // æ›´æ–°å›¾ç‰‡
      updateElement(newImageId, {
        src: imageResult.imageUrl,
        base64: imageResult.images?.[0]?.base64,
        promptId: imageResult.promptId,
        mediaId: imageResult.mediaId,
        mediaGenerationId: imageResult.mediaGenerationId,
        uploadState: 'synced',
      } as Partial<ImageElement>);

      // ç”ŸæˆæˆåŠŸåï¼Œåœæ­¢æ‰€æœ‰è¿çº¿åŠ¨ç”»
      // @ts-ignore
      setEdges((eds: any[]) =>
        eds.map((edge: any) =>
          edgeIds.includes(edge.id)
            ? { ...edge, animated: false, style: { stroke: '#10b981', strokeWidth: 1 } }
            : edge
        )
      );

      console.log('âœ… å›¾ç‰‡ç¼–è¾‘å®Œæˆï¼');

    } catch (error) {
      console.error('âŒ å›¾ç‰‡ç¼–è¾‘å¤±è´¥:', error);
      
      // å¦‚æœå¤±è´¥ï¼Œå°†æ‰€æœ‰è¿çº¿æ ‡è®°ä¸ºé”™è¯¯çŠ¶æ€
      // @ts-ignore
      setEdges((eds: any[]) =>
        eds.map((edge: any) =>
          edge.target === newImageId
            ? { ...edge, animated: false, style: { stroke: '#ef4444', strokeWidth: 1 } }
            : edge
        )
      );
    }
  }, [annotatorTarget, addElement, updateElement, setEdges]);

  // è¡Œçº§æ³¨é‡Šï¼šæ–‡ç”Ÿè§†é¢‘å¤„ç†å‡½æ•°
  const handleTextToVideo = useCallback(
    async (sourceNode: TextElement, aspectRatio: '9:16' | '16:9') => {
      resetConnectionMenu();

      let width: number;
      let height: number;
      if (aspectRatio === '9:16') {
        width = 270;
        height = 480;
      } else {
        width = 480;
        height = 270;
      }

      const newVideoId = `video-${Date.now()}`;
      const newVideo: VideoElement = {
        id: newVideoId,
        type: 'video',
        src: '',
        thumbnail: '',
        duration: 0,
        status: 'generating',
        progress: 0,
        position: {
          x: sourceNode.position.x + (sourceNode.size?.width || 200) + 100,
          y: sourceNode.position.y,
        },
        size: { width, height },
        promptText: sourceNode.text,
        generatedFrom: {
          type: 'text',
          sourceIds: [sourceNode.id],
          prompt: sourceNode.text,
        },
      };

      addElement(newVideo);

      // åˆ›å»ºè¿çº¿
      // @ts-ignore
      setEdges((eds: any[]) => [
        ...eds,
        {
          id: `edge-${sourceNode.id}-${newVideoId}-prompt-text`,
          source: sourceNode.id,
          target: newVideoId,
          targetHandle: 'prompt-text',
          type: 'default',
          animated: true,
          style: { stroke: '#a855f7', strokeWidth: 1 },
        },
      ]);

      try {
        const result = await generateVideoFromText(sourceNode.text, aspectRatio);

        updateElement(newVideoId, {
          status: 'ready',
          src: result.videoUrl,
          thumbnail: result.thumbnail,
          duration: result.duration,
          progress: 100,
          mediaGenerationId: result.mediaGenerationId,
          promptText: sourceNode.text,
          generatedFrom: {
            type: 'text',
            sourceIds: [sourceNode.id],
            prompt: sourceNode.text,
          },
        } as Partial<VideoElement>);

        // @ts-ignore
        setEdges((eds: any[]) =>
          eds.map((edge: any) =>
            edge.id === `edge-${sourceNode.id}-${newVideoId}-prompt-text`
              ? { ...edge, animated: false }
              : edge
          )
        );

        console.log('âœ… ä»æ–‡æœ¬èŠ‚ç‚¹ç”Ÿæˆè§†é¢‘:', sourceNode.text);
      } catch (error) {
        console.error('âŒ ç”Ÿæˆè§†é¢‘å¤±è´¥:', error);
        // @ts-ignore
        setEdges((eds: any[]) =>
          eds.map((edge: any) =>
            edge.id === `edge-${sourceNode.id}-${newVideoId}-prompt-text`
              ? { ...edge, animated: false, style: { stroke: '#ef4444', strokeWidth: 1 } }
              : edge
          )
        );
        alert('ç”Ÿæˆè§†é¢‘å¤±è´¥ï¼Œè¯·é‡è¯•');
      }
    },
    [addElement, updateElement, setEdges, resetConnectionMenu]
  );

  // è¡Œçº§æ³¨é‡Šï¼šå›¾ç”Ÿè§†é¢‘å¤„ç†å‡½æ•°
  const handleImageToVideo = useCallback(
    async (sourceNode: ImageElement, aspectRatio: '9:16' | '16:9') => {
      resetConnectionMenu();

      let width: number;
      let height: number;
      if (aspectRatio === '9:16') {
        width = 270;
        height = 480;
      } else {
        width = 480;
        height = 270;
      }

      const flowPosition = {
        x: sourceNode.position.x + (sourceNode.size?.width || 320) + 100,
        y: sourceNode.position.y,
      };

      // è¡Œçº§æ³¨é‡Šï¼šç›´æ¥è°ƒç”¨ç°æœ‰çš„ createVideoNodeFromImage å‡½æ•°
      createVideoNodeFromImage(sourceNode, flowPosition, 'start-image', 'right');

      console.log('âœ… ä»å›¾ç‰‡èŠ‚ç‚¹åˆ›å»ºè§†é¢‘èŠ‚ç‚¹:', sourceNode.id);
    },
    [createVideoNodeFromImage, resetConnectionMenu]
  );

  // å¤„ç†è¿çº¿è¿æ¥ï¼ˆç”Ÿæˆè§†é¢‘ï¼‰
  const handleConnect = useCallback(
    (connection: Connection) => {
      if (connectionStartRef.current) {
        connectionStartRef.current.didConnect = true;
      }

      const sourceId = connection.source;
      const targetId = connection.target;

      if (!sourceId || !targetId) {
        return;
      }

      const sourceNode = elements.find((el) => el.id === sourceId);
      const targetNode = elements.find((el) => el.id === targetId);

      if (!sourceNode || !targetNode) {
        return;
      }

      const edgeId = `edge-${sourceId}-${targetId}-${connection.targetHandle || 'default'}`;
      const upsertEdge = (animated = false, style = EDGE_DEFAULT_STYLE) => {
        // @ts-ignore
        setEdges((eds: any[]) => {
          const filtered = (eds as any[]).filter((edge: any) => edge.id !== edgeId);
          return [
            ...filtered,
            {
              id: edgeId,
              source: sourceId,
              target: targetId,
              sourceHandle: connection.sourceHandle,
              targetHandle: connection.targetHandle,
              type: (connection as any).type || 'default',
              animated,
              style,
            },
          ];
        });
      };

      // åªå…è®¸è¿æ¥åˆ°è§†é¢‘èŠ‚ç‚¹çš„è‡ªå®šä¹‰è¾“å…¥ï¼ˆåªæ”¯æŒå›¾ç‰‡è¿æ¥ï¼Œä¸æ”¯æŒæ–‡æœ¬è¿æ¥ï¼‰
      if (targetNode.type === 'video') {
        const targetHandle = connection.targetHandle;
        let handled = false;

        if (sourceNode.type === 'image' && targetHandle === 'start-image') {
          const imageNode = sourceNode as ImageElement;
          const videoData = targetNode as VideoElement;
          const sourceIds = new Set<string>(videoData.generatedFrom?.sourceIds ?? []);
          sourceIds.add(imageNode.id);
          if (videoData.endImageId) {
            sourceIds.add(videoData.endImageId);
          }
          const updates: Partial<VideoElement> = {
            startImageId: imageNode.id,
            startImageUrl: imageNode.src,
            generatedFrom: {
              type: 'image-to-image',
              sourceIds: Array.from(sourceIds),
              prompt: videoData.promptText,
            },
          };
          if (videoData.status === 'ready') {
            updates.status = 'pending';
            updates.progress = 0;
            updates.src = '';
            updates.thumbnail = '';
          }
          updateElement(targetId, updates);
          handled = true;
        } else if (sourceNode.type === 'image' && targetHandle === 'end-image') {
          const imageNode = sourceNode as ImageElement;
          const videoData = targetNode as VideoElement;
          const sourceIds = new Set<string>(videoData.generatedFrom?.sourceIds ?? []);
          if (videoData.startImageId) {
            sourceIds.add(videoData.startImageId);
          }
          sourceIds.add(imageNode.id);
          const updates: Partial<VideoElement> = {
            endImageId: imageNode.id,
            endImageUrl: imageNode.src,
            generatedFrom: {
              type: 'image-to-image',
              sourceIds: Array.from(sourceIds),
              prompt: videoData.promptText,
            },
          };
          if (videoData.status === 'ready') {
            updates.status = 'pending';
            updates.progress = 0;
            updates.src = '';
            updates.thumbnail = '';
          }
          updateElement(targetId, updates);
          handled = true;
        }

        if (!handled) {
          return;
        }

        upsertEdge();
        return;
      }

      // å…¶ä»–èŠ‚ç‚¹è¿æ¥ï¼Œç›´æ¥åˆ›å»ºè¿çº¿
      upsertEdge();
    },
    [elements, setEdges, updateElement]
  );

  return (
    <div ref={reactFlowWrapperRef} className="w-full h-full bg-gray-50 relative">
      {/* é¡¶éƒ¨å¯¼èˆª */}
      <CanvasNavigation />

      {/* å·¦ä¾§å·¥å…·æ  - èŠ‚ç‚¹åˆ›å»º */}
      <Toolbar />

      {/* å³ä¾§å·¥å…·æ  - åŠŸèƒ½æŒ‰é’® */}
      <RightToolbar />

      <ReactFlow
        className="custom-theme absolute inset-0"
        nodes={reactFlowNodes}
        edges={edges}
        onNodesChange={handleNodesChange}
        onEdgesChange={onEdgesChange}
        onNodeDrag={handleNodeDrag}
        onNodeDragStop={handleNodeDragStop}
        onSelectionChange={handleSelectionChange}
        onConnect={handleConnect}
        onConnectStart={handleConnectStart}
        onConnectEnd={handleConnectEnd}
        nodeTypes={nodeTypes}
        fitView
        selectNodesOnDrag={false}
        selectionMode={SelectionMode.Partial}
        selectionOnDrag
        panOnScroll
        panOnDrag={[1, 2]} // ä¸­é”®å’Œå³é”®æ‹–æ‹½
        zoomOnScroll
        minZoom={0.1}
        maxZoom={3}
        defaultViewport={{ x: 0, y: 0, zoom: 1 }}
        nodesDraggable={true}
        nodesConnectable={true}
        elementsSelectable={true}
        connectionLineStyle={{ stroke: '#a855f7', strokeWidth: 2 }}
        connectionLineType={ConnectionLineType.Bezier}
        proOptions={{ hideAttribution: true }}
      >
        {/* æ§åˆ¶å™¨ */}
        <Controls
          showInteractive={false}
          position="bottom-right"
          className="!bottom-24"
        />

        {/* èƒŒæ™¯ç½‘æ ¼ */}
        {uiState.showGrid && (
          <Background
            variant={BackgroundVariant.Dots}
            gap={40}
            size={4}
            color="#dddddd"
            bgColor="#f0f0f0"
          />
        )}

        {/* AI è¾“å…¥é¢æ¿ - æ”¾åœ¨ React Flow å†…éƒ¨ä»¥ä½¿ç”¨ useReactFlow */}
        <AIInputPanel />
      </ReactFlow>

      {/* è¡Œçº§æ³¨é‡Šï¼šè¿çº¿é€‰é¡¹èœå•ç»„ä»¶ */}
      <ConnectionMenuRoot
        state={connectionMenu}
        callbacks={{
          onShowImageSubmenu: showImageSubmenu,
          onShowVideoSubmenu: showVideoSubmenu,
          onGenerateImage: handleGenerateImage,
          onGenerateVideo: handleGenerateVideo,
          onImagePromptInputChange: handleImagePromptInputChange,
          onConfirmImagePrompt: handleConfirmImagePrompt,
          onBackToMain: backToMain,
          onBackToImageSubmenu: backToImageSubmenu,
          onClose: resetConnectionMenu,
        }}
        promptInputRef={promptMenuInputRef}
      />

      {/* å¤šé€‰å·¥å…·æ  */}
      <SelectionToolbar onMultiImageEdit={handleMultiImageEdit} />

      {/* å›¾ç‰‡ç¼–è¾‘å™¨ Modal - å…¨å±€æ¸²æŸ“ */}
      <ImageAnnotatorModal
        open={Boolean(annotatorTarget)}
        imageSrc={annotatorTarget?.src || null}
        isLoadingImage={isLoadingAnnotatorImage}
        mainImage={mainImageForEdit}
        referenceImages={referenceImages}
        onClose={handleAnnotatorClose}
        onConfirm={handleAnnotatorConfirm}
      />
    </div>
  );
}

export default function Canvas({ projectId }: { projectId?: string }) {
  return (
    <ReactFlowProvider>
      <CanvasContent projectId={projectId} />
    </ReactFlowProvider>
  );
}